#!/usr/bin/env python
# accessionator 0.0.1
# Generated by dx-app-wizard.
#
# Basic execution pattern: Your app will run on a single machine from
# beginning to end.
#
# See https://wiki.dnanexus.com/Developer-Portal for documentation and
# tutorials on how to modify this file.
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

import os, requests, logging, re, urlparse, subprocess, requests, json, shlex, time
import dxpy

try:
    DX_FS_ROOT = os.environ['DX_FS_ROOT']
except:
    DX_FS_ROOT = ""
KEYFILE = DX_FS_ROOT + '/keypairs.json'
DEFAULT_SERVER = 'https://www.encodeproject.org'
S3_SERVER='s3://encode-files/'
logger = logging.getLogger(__name__)

FILE_OBJ_TEMPLATE = {
        'lab': 'j-michael-cherry',
        'award': 'U41HG006992',
        'file_format': 'bam',
        'output_type': 'alignments',
        'assembly': 'GRCh38'
}


def processkey(key):

    if key:
        keysf = open(KEYFILE,'r')
        keys_json_string = keysf.read()
        keysf.close()
        keys = json.loads(keys_json_string)
        logger.debug("Keys: %s" %(keys))
        key_dict = keys[key]
    else:
        key_dict = {}
    AUTHID = key_dict.get('key')
    AUTHPW = key_dict.get('secret')
    if key:
        SERVER = key_dict.get('server')
    else:
        SERVER = 'https://www.encodeproject.org/'

    if not SERVER.endswith("/"):
        SERVER += "/"

    return (AUTHID,AUTHPW,SERVER)

def encoded_get(url, AUTHID=None, AUTHPW=None):
    HEADERS = {'content-type': 'application/json'}
    if AUTHID and AUTHPW:
        response = requests.get(url, auth=(AUTHID,AUTHPW), headers=HEADERS)
    else:
        response = requests.get(url, headers=HEADERS)
    return response

def encoded_post(url, AUTHID, AUTHPW, payload):
    HEADERS = {'content-type': 'application/json'}
    response = requests.post(url, auth=(AUTHID,AUTHPW), headers=HEADERS, data=json.dumps(payload))
    return response

def flagstat_parse(flagstat_file):
    if not flagstat_file:
        return None

    qc_dict = { #values are regular expressions, will be replaced with scores [hiq, lowq]
        'in_total': 'in total',
        'mapped': 'mapped',
        'paired_in_sequencing': 'paired in sequencing',
        'read1': 'read1',
        'read2': 'read2',
        'properly_paired': 'properly paired',
        'with_self_mate_mapped': 'with itself and mate mapped',
        'singletons': 'singletons',
        'mate_mapped_different_chr': 'with mate mapped to a different chr$', #i.e. at the end of the line
        'mate_mapped_different_chr_hiQ': 'with mate mapped to a different chr \(mapQ>=5\)' #RE so must escape
    }
    flagstat_lines = flagstat_file.read().splitlines()
    for (qc_key, qc_pattern) in qc_dict.items():
        qc_metrics = next(re.split(qc_pattern, line) for line in flagstat_lines if re.search(qc_pattern, line))
        (hiq, lowq) = qc_metrics[0].split(' + ')
        qc_dict[qc_key] = [int(hiq.rstrip()), int(lowq.rstrip())]

    return qc_dict


@dxpy.entry_point('main')
def main(folder_name, key_name, debug):

    if debug:
        logger.setLevel(logging.DEBUG)
    else:
        logger.setLevel(logging.INFO)

    if not folder_name.startswith('/'):
    	folder_name = '/' + folder_name

    try:
        project = dxpy.DXProject(dxpy.PROJECT_CONTEXT_ID)
        project_name = project.describe().get('name')
    except:
        print "Project not found"
        project_name = ""

 
    bams = dxpy.find_data_objects(
    	classname="file",
    	state="closed",
    	name="*.bam",
    	name_mode="glob",
    	project=dxpy.PROJECT_CONTEXT_ID,
    	folder=folder_name,
    	recurse=True,
    	return_handler=True
	)

    authid, authpw, server = processkey(key_name)
    if not subprocess.call('which md5', shell=True):
        md5_command = 'md5 -q'
    elif not subprocess.call('which md5sum', shell=True):
        md5_command = 'md5sum'
    else:
        print "Cannot find md5 or md5sum command"
        md5_command = ''

    file_mapping = []
    for bam in bams:
        bam_description = bam.describe()
        submitted_file_name = project_name + ':' + '/'.join([bam.folder,bam.name])
        submitted_file_size = bam_description.get('size')
        url = urlparse.urljoin(server, 'search/?type=file&submitted_file_name=%s&format=json&frame=object' %(submitted_file_name))
        r = encoded_get(url,authid,authpw)
        try:
            r.raise_for_status()
            if r.json()['@graph']:
                duplicate_item = r.json()['@graph'][0]
                print "Found potential duplicate: %s" %(duplicate_item.get('accession'))
                if submitted_file_size ==  duplicate_item.get('file_size'):
                    print "%s %s: File sizes match, assuming duplicate." %(str(submitted_file_size), duplicate_item.get('file_size'))
                else:
                    print "%s %s: File sizes differ, assuming new file." %(str(submitted_file_size), duplicate_item.get('file_size'))
                    duplicate_item = {}
            else:
                print "No duplicate ... proceeding"
                duplicate_item = {}
        except:
            print('Duplicate accession check failed: %s %s' % (r.status_code, r.reason))
            print(r.text)
            duplicate_item = {}

        if duplicate_item:
            print "Duplicate detected, skipping"
            continue

        experiment_accession = re.match('\S*(ENC\S{8})',bam.folder).group(1)
        print "Downloading %s" %(bam.name)
        dxpy.download_dxfile(bam.get_id(),bam.name)
        md5_output = subprocess.check_output(' '.join([md5_command, bam.name]), shell=True)
        calculated_md5 = md5_output.partition(' ')[0].rstrip()
        encode_object = FILE_OBJ_TEMPLATE
        try:
            bamqc = dxpy.find_one_data_object(
                classname="file",
                name=bam.name + '.flagstat.qc',
                project=dxpy.PROJECT_CONTEXT_ID,
                folder=bam.folder,
                return_handler=True
            )
        except:
            print "Flagstat file not found ... skipping QC"
            bamqc = None
        notes = {
            'qc': flagstat_parse(bamqc),
            'dx-id': bam_description.get('id'),
            'dx-createdBy': bam_description.get('createdBy')
        }
        encode_object.update({
            'dataset': experiment_accession,
            'notes': json.dumps(notes),
            'submitted_file_name': submitted_file_name,
            'derived_from': re.findall('(ENCFF\S{6})',bam.name),
            'file_size': submitted_file_size,
            'md5sum': calculated_md5
            })
        print "Experiment accession: %s" %(experiment_accession)
        print "File metadata: %s" %(encode_object)

        url = urlparse.urljoin(server,'files')
        r = encoded_post(url, authid, authpw, encode_object)
        try:
            r.raise_for_status()
            item = r.json()['@graph'][0]
            print "New accession: %s" %(item.get('accession'))
        except:
            print('POST file object failed: %s %s' % (r.status_code, r.reason))
            print(r.text)
            item = {}

        if item:
            creds = item['upload_credentials']
            env = os.environ.copy()
            env.update({
                'AWS_ACCESS_KEY_ID': creds['access_key'],
                'AWS_SECRET_ACCESS_KEY': creds['secret_key'],
                'AWS_SECURITY_TOKEN': creds['session_token'],
            })

            print("Uploading file.")
            start = time.time()
            try:
                subprocess.check_call(['aws', 's3', 'cp', bam.name, creds['upload_url'], '--quiet'], env=env)
            except subprocess.CalledProcessError as e:
                # The aws command returns a non-zero exit code on error.
                print("Upload failed with exit code %d" % e.returncode)
                upload_returncode = e.returncode
            else:
                upload_returncode = 0
                end = time.time()
                duration = end - start
                print("Uploaded in %.2f seconds" % duration)
        else:
            upload_returncode = -1

        out_string = '\t'.join([
            experiment_accession,
            encode_object.get('submitted_file_name'),
            item.get('accession') or '',
            str(upload_returncode),
            encode_object.get('notes')
        ])
        print out_string
        file_mapping.append(out_string)

    output_log_filename = time.strftime('%m%d%y%H%M') + '-accession_log.csv'
    out_fh = dxpy.upload_string('\n'.join(file_mapping), name=output_log_filename, media_type='text/csv')
    out_fh.close()

    output = {
        "file_mapping": file_mapping,
        "outfile": dxpy.dxlink(out_fh)
    }

    return output

dxpy.run()
